To gain deeper insights of the proposed method, we visualized the internal representations of the fixed and the fine-tuning convolutional layers based on the same song clip in the target task. From top to bottom in each graph, they are: 1) log mel spectrogram of the audio clip; 2) the output of L<SUB>i</SUB> in Fine-tuning mode in the target task; 3) the output of L<SUB>i</SUB> in Fixed mode in the target task.<p></p>

Due to the limitation of space, the internal representations of one feature map, which was randomly selected from the feature maps, In these Figures, L<SUB>1</SUB> learns more obvious basic local features of the input spectrogram than L<SUB>2</SUB> and L<SUB>3</SUB>. The L<SUB>1</SUB> after fine-tuning, whose representations of high frequency harmonics are abundant, learns more high frequency harmonic components than that of fixed one. The fine-tuned and retrained L<SUB>1</SUB> preserves features of the input audio clip better and matches the target domain more closely<p></p>