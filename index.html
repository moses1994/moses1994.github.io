<style>
audio {
 max-width: 100%;
}
 .tab {
 min-width: 100%;
 }
</style>
<h1 align="center"> Transfer Learning for Improving Singing Voice Detection in Polyphonic Instrumental Music <p></p></h1>

<div width="100%">

<h2 align="left"><a name="part1">1. Some synthesized audio clip samples in the source task</a><p></p></h2>
            

<table class="tab">
<tr>
<td><audio  controls><source src="1-synthesized-speech-plus-music-clips-samples-in-the-source-task/BAC009S0022W0166.wav"></audio></td>            
<td><audio  controls><source src="1-synthesized-speech-plus-music-clips-samples-in-the-source-task/BAC009S0022W0167.wav"></audio></td>      
<td><audio  controls><source src="1-synthesized-speech-plus-music-clips-samples-in-the-source-task/BAC009S0022W0170.wav"></audio></td>      
<td><audio  controls><source src="1-synthesized-speech-plus-music-clips-samples-in-the-source-task/BAC009S0022W0218.wav"></audio></td>      
<td><audio  controls><source src="1-synthesized-speech-plus-music-clips-samples-in-the-source-task/BAC009S0022W0219.wav"></audio></td> 
</tr>
<tr>      
<td><audio  controls><source src="1-synthesized-speech-plus-music-clips-samples-in-the-source-task/BAC009S0022W0234.wav"></audio></td>            
<td><audio  controls><source src="1-synthesized-speech-plus-music-clips-samples-in-the-source-task/BAC009S0022W0393.wav"></audio></td>      
<td><audio  controls><source src="1-synthesized-speech-plus-music-clips-samples-in-the-source-task/BAC009S0022W0402.wav"></audio></td>      
<td><audio  controls><source src="1-synthesized-speech-plus-music-clips-samples-in-the-source-task/BAC009S0022W0404.wav"></audio></td>      
<td><audio  controls><source src="1-synthesized-speech-plus-music-clips-samples-in-the-source-task/BAC009S0022W0461.wav"></audio></td>  
</tr>    
</table>

<h2 align="left"><a name="part2">2. Some polyphonic music samples in the target task</a><p></p></h2>           
<table class="tab">
<tr>
<td><audio  controls><source src="2-polyphonic-music-samples-in-the-target-task/BaiHuaGe_ZhouXuan-1.wav"></audio></td>    
<td><audio  controls><source src="2-polyphonic-music-samples-in-the-target-task/zhuimengchizixin_GALA-1.wav"></audio></td>        
<td><audio  controls><source src="2-polyphonic-music-samples-in-the-target-task/BaLuoBo_YiMing-1.wav"></audio></td>   
<td><audio  controls><source src="2-polyphonic-music-samples-in-the-target-task/yekongzhongzuishanliangdexing_taopaojihua-1.wav"></audio></td>   
<td><audio  controls><source src="2-polyphonic-music-samples-in-the-target-task/HaiKuoTianKong_LiWeiZhen-1.wav"></audio></td> 
</tr>
</table>

</div> 

<h2 align="left"><a name="part3">3. Patterns of different filters in L<SUB>i</SUB>, for each subgraph, the x-axis is time (T) and the y-axis is frequency (F).</a><p></p></h2> 

<div align="center">
<img src="fig.4.png" width=50%/>
</div>

<h3 align="center"> For more details on the filter patterns learned in the source task, please <a href="https://github.com/moses1994/singing-voice-detection/tree/master/3-filter-patterns-learned-in-source-task" target="https://github.com/moses1994/singing-voice-detection/tree/master/3-filter-patterns-learned-in-source-task">visit here</a>
 : https://github.com/moses1994/singing-voice-detection/tree/master/3-filter-patterns-learned-in-source-task
<p></p></h3>
 
 
<h3 align="center"> For more details on the filter patterns learned in the target task, please <a href="https://github.com/moses1994/singing-voice-detection/tree/master/3-filter-patterns-learned-in-target-task" target="https://github.com/moses1994/singing-voice-detection/tree/master/3-filter-patterns-learned-in-target-task">visit here</a>
 : https://github.com/moses1994/singing-voice-detection/tree/master/3-filter-patterns-learned-in-target-task
<p></p></h3>

<h2 align="left"><a name="part3">4. Some internal representations of feature maps in audio clips</a><p></p></h2>   

<h3 align="left"> 
To gain deeper insights of the proposed method, we visualized the internal representations of the fixed and the fine-tuning convolutional layers based on the same song clip in the target task. From top to bottom in each graph, they are: 1) log mel spectrogram of the audio clip; 2) the output of L<SUB>i</SUB> in Fine-tuning mode in the target task; 3) the output of L<SUB>i</SUB> in Fixed mode in the target task.<p></p>

Due to the limitation of space, the internal representations of one feature map, which was randomly selected from the feature maps, In these Figures, L<SUB>1</SUB> learns more obvious basic local features of the input spectrogram than L<SUB>2</SUB> and L<SUB>3</SUB>. The L<SUB>1</SUB> after fine-tuning, whose representations of high frequency harmonics are abundant, learns more high frequency harmonic components than that of fixed one. The fine-tuned and retrained L<SUB>1</SUB> preserves features of the input audio clip better and matches the target domain more closely<p></p>

For more samples about the internal representations learned in the target task, please <a href="https://github.com/moses1994/singing-voice-detection/tree/master/4-internal-representations-of-feature-maps" 
target="https://github.com/moses1994/singing-voice-detection/tree/master/4-internal-representations-of-feature-maps">visit here</a>
 : https://github.com/moses1994/singing-voice-detection/tree/master/4-internal-representations-of-feature-maps
<p></p></h3>

<h3 align="center"> polyphonic music clip: 1 <p></p></h3>
<div align="center">
<img src="4-internal-representations-of-feature-maps/music-clip-1-l1.png" width=33%/>
<img src="4-internal-representations-of-feature-maps/music-clip-1-l2.png" width=33%/> 
<img src="4-internal-representations-of-feature-maps/music-clip-1-l3.png" width=33%/>
</div>  

<h3 align="center"> polyphonic music clip: 2 <p></p></h3>
<div align="center">
<img src="4-internal-representations-of-feature-maps/music-clip-3-l1.png" width=33%/>
<img src="4-internal-representations-of-feature-maps/music-clip-3-l2.png" width=33%/> 
<img src="4-internal-representations-of-feature-maps/music-clip-3-l3.png" width=33%/>
</div>  


<h2 align="left"><a name="part4">5. Final singing-voice detection results for some polyphonic songs</a><p></p></h2> 

<h3> In these videos, the middle black vertical line represents the current playback position, the blue lines indicate the raw audio waves, the yellow block represents the singing voice activity, and the gray block indicates the non-singing area. <p></p></h3>
  
<h3 align="center"> Song 1: Gaosuwo <p></p></h3>
<div align="center">
<video width=95%/ controls>
<source src="5-videos-of-final-test-results/gaosuwo.mp4" type="video/mp4">   
</video>
</div>  

<h3 align="center"> Song 2: Haoxianghaoxiang <p></p></h3>
<div align="center">
<video width=95%/ controls>
<source src="5-videos-of-final-test-results/haoxianghaoxiang.mp4" type="video/mp4">   
</video>
</div>  

<h3 align="center"> Song 3: Duolaimi <p></p></h3>
<div align="center">
<video width=95%/ controls>
<source src="5-videos-of-final-test-results/duolaimi.mp4" type="video/mp4">   
</video>
</div>  

<h3 align="center"> Song 4: Mote <p></p></h3>
<div align="center">
<video width=95%/ controls>
<source src="5-videos-of-final-test-results/mote.mp4" type="video/mp4">   
</video>
</div>    

<h3 align="center"> It is noteworthy that after transfer learning, the CRNN model in the target task detected the “thanks” voice of the singer to the audience at the concert, at 4:39 seconds of the fourth song named “Mote.wav”. However, the baseline system trained in the target task did not detect it. This may be due to the speech data in the source task has voice samples related to "thank you", and after transfer learning, the CRNN model in the target task absorbed these knowledge.
 <p></p></h3>


<h2 align="left"><a name="part4">6. The results of two different transfer modes and the detection results in frame-level. </a><p></p></h2> 

<h3 align="center"> Table 1: The results of two different transfer modes.  <p></p></h3>
<div align="center">
<img src="6-tables/table1.PNG" width=50%/>
</div>  

<h3 align="center"> Table 2: The detection results in frame-level.  <p></p></h3>
<div align="center">
<img src="6-tables/table2.PNG" width=50%/>
</div>

<!--
<video width="1600" height="720" controls>

第二张

<div align="center"><img src="5-internal-representations-of-feature-maps/music-clip-1-l1.png" width="350" /></div>

第三张

<img src="5-internal-representations-of-feature-maps/music-clip-1-l1.png" style="transform:scale(0.5)" /><br/> 

<img src="5-internal-representations-of-feature-maps/music-clip-1-l1.png" style="transform:scale(0.8)" /><br/> 

<img src="5-internal-representations-of-feature-maps/music-clip-1-l1.png" style="transform:scale(1)" /><br/> 

-->



